{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7298e9-1b86-49a8-999b-377654944998",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa89622-8664-4ad6-b646-cc6c7bc91c7e",
   "metadata": {},
   "source": [
    "I conducted the exploratory analysis (EDA) in R (see eda.Rmd), and this part of the notebook deals with preparing the data using what I found from the EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80101c4a-06be-4254-8776-5124577e9d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_main import Data\n",
    "\n",
    "data = Data();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec1e10-3d8e-496b-a957-ee084a56ddd3",
   "metadata": {},
   "source": [
    "Creating an instance of the Data class reads the data csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a752e8c-0f16-4168-8040-f51feae87f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivori\\Documents\\id5059\\deposits-predictor\\src\\data_main.py:49: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.data[\"response\"] = self.data[\"y\"].replace({\"no\": 0, \"yes\": 1});\n"
     ]
    }
   ],
   "source": [
    "data._Data__convert_response();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011d1bf-2b17-4b73-acec-3208e0ee69cd",
   "metadata": {},
   "source": [
    "I convert the response variable to boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f255758f-7f3a-4a79-921e-539416158dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data._Data__create_day_ids();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0290e6f-fb80-4e08-84aa-f90b948568ef",
   "metadata": {},
   "source": [
    "The EDA revealed this data has a significant temporal component. Given the data is ordered and I have days of week, I can create a helper column called \"new_day\" to mark changes in the day of week, and cumulatively sum over it to get a \"day_id\" or the number of days elapsed since data collection started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd941536-c3de-451a-82b5-71c27bd74120",
   "metadata": {},
   "outputs": [],
   "source": [
    "data._Data__convert_to_categorical();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5fd244-7e5d-4f47-9da2-3b6a3758d2a9",
   "metadata": {},
   "source": [
    "I convert all string columns to categorical values. The EDA identified that some numerical variables would be inappropriate to represent as continuous (i.e previous), so I convert them to categorical as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653986b6-2e69-4fc7-8348-4bc7a9579867",
   "metadata": {},
   "outputs": [],
   "source": [
    "data._Data__merge(\"loan\", \"housing\");\n",
    "data._Data__merge(\"poutcome\", \"previous\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc03f8-1e8a-478e-a4d0-46595a77e23d",
   "metadata": {},
   "source": [
    "EDA identified that these columns need to be merged for linear models because some levels of this category are perfectly multcolinear with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "563a3466-d2f5-4a37-8f60-1a0f5537df0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivori\\Documents\\id5059\\deposits-predictor\\src\\data_main.py:119: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  self.data[\"default_group\"] = self.data[\"default\"].replace({\"unknown\": \"unknown_or_yes\", \"yes\": \"unknown_or_yes\"});\n"
     ]
    }
   ],
   "source": [
    "data._Data__bin_continuous();\n",
    "data._Data__bin_categorical();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790d0c07-896a-4711-998b-ab8eac386850",
   "metadata": {},
   "source": [
    "EDA showed densities of certain non-linear continuous variables are neatly seperated by class at some thresholds (age, pdays, campaign) so linear models can use them to seperate between classes. Similarly, certain categoricals (default) have some unecessary levels that can be removed to reduce their complexity and standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c9127b-3122-4520-ae71-ec99303039c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data._Data__encode_categorical();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7b888f-a337-457c-84d8-b5bea826f8f2",
   "metadata": {},
   "source": [
    "I perform one-hot encoding of all categorical variables to make it easier for models to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7ee69d-f5a7-4e68-bbe2-ecb3003425fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data._Data__remove_unfair_predictors();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994a05-244b-4735-856e-71459ed8ef0c",
   "metadata": {},
   "source": [
    "Some predictors (duration) are only known after a recording is complete, so need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c099570a-9991-4399-b6ff-3a98b8db322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data._Data__split_data();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b688db08-a058-4fd1-aeb3-3de240073250",
   "metadata": {},
   "source": [
    "The EDA identified a significant temporal component to the data. To produce genuine predictions in the future, a successful model needs to be able to infer temporal patterns in the data using day_id. I choose to split the data based on day_id. The idea here is to train the model on a lot of historical data with different temporal patterns (e.g the strategy shifts identified in EDA) so the model learns these different patterns, then test them on the most recent data. Given the most recent days contain the fewest records, a balance needs to be struck between showing the model enough of the most recent temporal pattern and restricting the size of the training data to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90cfda6d-64e7-499c-96fa-458d14d59022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(260.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d964c5-24d9-434e-93ab-6cdbd7e00af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06958337379819365"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.test_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1310cdc6-5515-4a6d-9fcf-90553ff8df9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304166262018063"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e958224-4276-4489-ada0-c10e1bc33b46",
   "metadata": {},
   "source": [
    "This proportion of training is higher than normal (0.8), so models trained with this split have a tendancy to overfit to the training data, but is necessary for the model to learn about the most recent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cd4a7e9-9f3a-461f-906c-0c25df4cd943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "False    36548\n",
       "True      4640\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[\"response\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc326e7-b1ff-4353-96cf-5c4019701de2",
   "metadata": {},
   "source": [
    "The data as a whole has a class imbalance, but EDA identified that the class balance becomes more equal for more recent observations. Data split using the above splitting schema will have different balances for training and testing data, so I oversample the True class in the training data so a) it resembles the split of the testing data and b) it learns characteristics of True at the same level as False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b2017-aeaa-45a3-aa52-ddf0299682ba",
   "metadata": {},
   "source": [
    "Linear models (e.g GAM fitted during EDA) sometimes work best with non-linear continuous by binning and need some adjustments to avoid perfect multicolinearity, whereas machine learning models (e.g DecisionTree, RandomForest, SGD) work best by inferring the bins themselves and need no such adjustments. I create two sets of data: \"sensitive\" for linear models and \"insensitive\" for ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc0f8fae-12be-4105-8fc2-712debe177af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'campaign', 'pdays', 'emp.var.rate', 'cons.price.idx',\n",
       "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'job_admin.',\n",
       "       'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
       "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
       "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
       "       'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'education_basic.4y', 'education_basic.6y',\n",
       "       'education_basic.9y', 'education_high.school', 'education_illiterate',\n",
       "       'education_professional.course', 'education_university.degree',\n",
       "       'education_unknown', 'default_no', 'default_unknown', 'default_yes',\n",
       "       'housing_no', 'housing_unknown', 'housing_yes', 'loan_no',\n",
       "       'loan_unknown', 'loan_yes', 'contact_cellular', 'contact_telephone',\n",
       "       'month_apr', 'month_aug', 'month_dec', 'month_jul', 'month_jun',\n",
       "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
       "       'day_of_week_fri', 'day_of_week_mon', 'day_of_week_thu',\n",
       "       'day_of_week_tue', 'day_of_week_wed', 'previous_0', 'previous_1',\n",
       "       'previous_2', 'previous_3', 'previous_4', 'previous_5', 'previous_6',\n",
       "       'previous_7', 'poutcome_failure', 'poutcome_nonexistent',\n",
       "       'poutcome_success'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.insensitive_train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "927e9812-b2de-442a-a8d1-1f60e3b9db9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m',\n",
       "       'nr.employed', 'job_admin.', 'job_blue-collar', 'job_entrepreneur',\n",
       "       'job_housemaid', 'job_management',\n",
       "       ...\n",
       "       'campaign_group_2', 'campaign_group_3', 'campaign_group_4',\n",
       "       'campaign_group_5', 'campaign_group_6', 'campaign_group_7',\n",
       "       'campaign_group_8', 'campaign_group_9+', 'default_group_no',\n",
       "       'default_group_unknown_or_yes'],\n",
       "      dtype='object', length=126)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sensitive_train_X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f37a3c2-b697-4b88-b96b-34c78f7ab859",
   "metadata": {},
   "source": [
    "Finally, I create validation sets from a random sample of 20% of the training data to tune hyperparameters and decision thresholds with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0531149-45ad-4d17-ab0d-0e12e8b792ff",
   "metadata": {},
   "source": [
    "**Modelling and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26c0c038-e6ae-45c2-b259-b0fb0c80c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models_main import Models\n",
    "\n",
    "models = Models(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e411eb5-7fbd-4c12-be58-d63d41090220",
   "metadata": {},
   "source": [
    "Creating an instance of the Models class initialises the three classifier I chose: a Stochastic Gradient Descent (SGD), a Decision Tree (DT), and a Random Forest (RF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4824a-8a5c-4dc5-861a-cd00980a6a0d",
   "metadata": {},
   "source": [
    "Every model I chose has \"hyperparameters\", or characteristics about the model that are not changed when trained on different data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e8d02a4-b107-4c72-ba3b-91ce819afe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print a given list of objects in a user-friendly format\n",
    "@param list_dict: list of dictionaries\n",
    "\"\"\"\n",
    "def print_list(list_dict):\n",
    "    for dictionary in list_dict:\n",
    "        print(dictionary);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba26e4e1-07ec-4b66-9bf0-064e6e0878d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SGD': {'estimator__loss': ['hinge', 'log_loss', 'modified_huber'], 'estimator__penalty': ['l2', 'l1', 'elasticnet'], 'estimator__alpha': [0.0001, 0.001, 0.01], 'estimator__max_iter': [1000, 2000], 'estimator__tol': [0.001, 0.0001], 'method': ['sigmoid'], 'cv': [5], 'estimator__random_state': [42]}}\n",
      "{'Decision Tree': {'max_depth': [None, 20, 40, 60], 'max_leaf_nodes': [None, 20, 50, 100], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'criterion': ['gini', 'entropy']}}\n",
      "{'Random Forest': {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}}\n"
     ]
    }
   ],
   "source": [
    "print_list(\n",
    "    models.get_param_grids()\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693492e1-4f0c-4f7f-91e8-b318c210a849",
   "metadata": {},
   "source": [
    "I search through every possible combination of these hyperparameters (GridSearchCV) and choose the combination of hyperparameters that produce a model with the highest f1 score when trained on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b527b1c9-e5b1-4da0-9741-0ac4befa55cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SGD': {'cv': 5, 'estimator__alpha': 0.0001, 'estimator__loss': 'hinge', 'estimator__max_iter': 1000, 'estimator__penalty': 'elasticnet', 'estimator__random_state': 42, 'estimator__tol': 0.0001, 'method': 'sigmoid'}}\n",
      "{'Decision Tree': {'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 2}}\n",
      "{'Random Forest': {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}}\n"
     ]
    }
   ],
   "source": [
    "models.tune(load_path = \"src/hyperparameters.json\");\n",
    "\n",
    "print_list(\n",
    "    models.get_params()\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf8d1d-2cf2-4f5c-882c-c5f89a2e676e",
   "metadata": {},
   "source": [
    "I train the models using these hyperparameters. All chosen models are trained on the \"insensitive\" training sets and produce probabilities of \"response\" being True (including SGD, which I wrap in a Platt scaler to convert distance to the decision boundary to a probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fa8833d-f149-4d1c-b4e1-78d038aadb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 3/3 [00:18<00:00,  6.18s/it]\n"
     ]
    }
   ],
   "source": [
    "models.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf519b-0441-4881-8a5c-7e70510eefb7",
   "metadata": {},
   "source": [
    "Once trained, I select a \"decision threshold\", above which a produced probability prediction will be classed as \"True\", to maximise F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a38d9f9-7bd7-4586-a729-ab6737db4cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SGD': np.float64(0.0)}\n",
      "{'Decision Tree': np.float64(0.01)}\n",
      "{'Random Forest': np.float64(0.47000000000000003)}\n"
     ]
    }
   ],
   "source": [
    "print_list(\n",
    "    models.get_thresholds()\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ae774-7ae5-40f4-9b4f-475c8c544bea",
   "metadata": {},
   "source": [
    "Note the strangely low thresholds of SGD and DT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10fe2e68-dd89-40b6-ad11-ba813e8e22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.evaluate();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79bcc3-d5b4-44c8-a01c-1ad04408d7ff",
   "metadata": {},
   "source": [
    "Hyperparameters and decision thresholds have been selected to maximise F1, and I evaluate my models using F1 and an ROC curve. I choose F1 because a false-positive is equally bad as a false-negative, and these metrics are robust to our class imbalance (e.g unlike Youden's J)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3412d4cd-c076-4ac6-ad9e-f1d950df76c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SGD': np.float64(0.6740689336109184)}\n",
      "{'Decision Tree': np.float64(0.4602692140686062)}\n",
      "{'Random Forest': np.float64(0.44105011933174226)}\n",
      "{'SGD': {'true_positive': np.int64(1457), 'false_positive': np.int64(1409), 'true_negative': np.int64(0), 'false_negative': np.int64(0)}}\n",
      "{'Decision Tree': {'true_positive': np.int64(530), 'false_positive': np.int64(316), 'true_negative': np.int64(1093), 'false_negative': np.int64(927)}}\n",
      "{'Random Forest': {'true_positive': np.int64(462), 'false_positive': np.int64(176), 'true_negative': np.int64(1233), 'false_negative': np.int64(995)}}\n"
     ]
    }
   ],
   "source": [
    "print_list(\n",
    "    models.get_f1s()\n",
    ");\n",
    "\n",
    "print_list(\n",
    "    models.get_confusion_matrices()\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc48036-9092-411e-a33e-6989fb2ac7e9",
   "metadata": {},
   "source": [
    "SGD's high F score is misleading as it always predicts \"True\" meaning it has failed. The remaining F1 scores are disappointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8584e60b-8bf4-47b0-a7ab-4ea898611ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SGD': [np.float64(0.1874011373959083), np.float64(0.7203909017508012)]}\n",
      "{'Decision Tree': [np.float64(0.0), np.float64(1.0)]}\n",
      "{'Random Forest': [np.float64(0.06), np.float64(0.93)]}\n"
     ]
    }
   ],
   "source": [
    "print_list(\n",
    "    models.get_pred_ranges()\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f5e3d-dcbd-4d60-9ef5-2711695b94a8",
   "metadata": {},
   "source": [
    "SGD does not produce predictions distributed across the entire probability space [0,1] unlike DT or (mostly) RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e45cf5d-daa7-4613-aecf-eedd961f8be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SGD': np.float64(-0.07393706457717245)}\n",
      "{'Decision Tree': np.float64(0.08048696125210984)}\n",
      "{'Random Forest': np.float64(0.14037842751366153)}\n"
     ]
    }
   ],
   "source": [
    "print_list(\n",
    "    models.get_roc_integrals()\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c195d-c411-4fa5-bd19-d904d93626b6",
   "metadata": {},
   "source": [
    "From the two working models, DT has the higher performance (F1 score) the optimised threshold but RF has the highest performance across all possible thresholds (area underneath ROC curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a150130d-e041-4ead-a5b1-1d7aa89add49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SGD': [np.float64(0.5083740404745289), np.float64(1.0)]}\n",
      "{'Decision Tree': [np.float64(0.6264775413711584), np.float64(0.363761153054221)]}\n",
      "{'Random Forest': [np.float64(0.7241379310344828), np.float64(0.31708991077556625)]}\n"
     ]
    }
   ],
   "source": [
    "print_list(\n",
    "    models.get_precisions_recalls()\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8f7e4-60b4-4230-8a9d-26ff6951e98d",
   "metadata": {},
   "source": [
    "DT has a lower precision but a higher recall than RF at their optimal thresholds, but this situation weights false positives and false negatives equally so cannot be a basis for model selection. I choose the model with the highest harmonic mean between precision and recall, DT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78f4dd79-454d-492d-82af-2e05fffadc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SGD': np.float64(0.6666666666666666)}\n",
      "{'Decision Tree': np.float64(0.9960457502444832)}\n",
      "{'Random Forest': np.float64(0.9960457502444832)}\n",
      "{'SGD': {'true_positive': np.int64(35139), 'false_positive': np.int64(35139), 'true_negative': np.int64(0), 'false_negative': np.int64(0)}}\n",
      "{'Decision Tree': {'true_positive': np.int64(35139), 'false_positive': np.int64(279), 'true_negative': np.int64(34860), 'false_negative': np.int64(0)}}\n",
      "{'Random Forest': {'true_positive': np.int64(35139), 'false_positive': np.int64(279), 'true_negative': np.int64(34860), 'false_negative': np.int64(0)}}\n"
     ]
    }
   ],
   "source": [
    "print_list(\n",
    "    models.get_train_f1s()\n",
    ");\n",
    "\n",
    "print_list(\n",
    "    models.get_train_confusion_matrices()\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316cb2a-a228-4199-a032-5813263491d5",
   "metadata": {},
   "source": [
    "SGD also predicted \"yes\" naively during training, but the other models have nearly perfectly overfitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64175675-0ed5-49ff-9d71-1fbdcd66e7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivori\\Documents\\id5059\\deposits-predictor\\src\\data_main.py:49: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.data[\"response\"] = self.data[\"y\"].replace({\"no\": 0, \"yes\": 1});\n",
      "C:\\Users\\ivori\\Documents\\id5059\\deposits-predictor\\src\\data_main.py:119: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  self.data[\"default_group\"] = self.data[\"default\"].replace({\"unknown\": \"unknown_or_yes\", \"yes\": \"unknown_or_yes\"});\n",
      "100%|████████████████████████████████████████| 3/3 [00:36<00:00, 12.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# Retrain models on data without days\n",
    "data_no_day = Data();\n",
    "data_no_day.preprocess(remove_day_ids = True);\n",
    "models_no_day = Models(data_no_day);\n",
    "models_no_day.tune(load_path = \"src/no_day_hyperparameters.json\");\n",
    "models_no_day.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7cb622d-9a4e-4231-9700-16796da3ad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_id removved successfully\n"
     ]
    }
   ],
   "source": [
    "# Check that models have no access to day_id\n",
    "try:\n",
    "    print(models.models[0].train_X[\"day_id\"]);\n",
    "except KeyError:\n",
    "    print(\"day_id removved successfully\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1606c06-2339-47d4-bb97-c8900278fc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SGD': np.float64(0.6740689336109184)}\n",
      "{'Decision Tree': np.float64(0.45021645021645024)}\n",
      "{'Random Forest': np.float64(0.5445887445887446)}\n",
      "{'SGD': np.float64(0.6666666666666666)}\n",
      "{'Decision Tree': np.float64(0.9960457502444832)}\n",
      "{'Random Forest': np.float64(0.9960457502444832)}\n",
      "{'SGD': {'true_positive': np.int64(1457), 'false_positive': np.int64(1409), 'true_negative': np.int64(0), 'false_negative': np.int64(0)}}\n",
      "{'Decision Tree': {'true_positive': np.int64(520), 'false_positive': np.int64(333), 'true_negative': np.int64(1076), 'false_negative': np.int64(937)}}\n",
      "{'Random Forest': {'true_positive': np.int64(629), 'false_positive': np.int64(224), 'true_negative': np.int64(1185), 'false_negative': np.int64(828)}}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate no_day models\n",
    "models_no_day.evaluate()\n",
    "print_list(\n",
    "    models_no_day.get_f1s()\n",
    ")\n",
    "print_list(\n",
    "    models_no_day.get_train_f1s()\n",
    ")\n",
    "print_list(\n",
    "    models_no_day.get_confusion_matrices()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4958c-3146-4be4-a93d-4372655b09ae",
   "metadata": {},
   "source": [
    "SGD without day ID still fails. RF and DT without day IDs still overfit extremely in training, but produces better testing performance than including them. Random forest becomes the better model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
